{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据的标准化（normalization）是将数据按比例缩放，使之落入一个小的特定区间。在某些比较和评价的指标处理中经常会用到，去除数据的单位限制，将其转化为无量纲的纯数值，便于不同单位或量级的指标能够进行比较和加权。\n",
    "\n",
    "常见的标准化方法，可以大体上分为三个类别：\n",
    "* 中心化（Centering）：将所有数据减去均值，让数据分布在 0 值左右而非均值左右，聚焦于数据的差异；\n",
    "* 缩放（Scaling）：将数据统一乘或者除一个因子，消除量级差异，有多种缩放方法适应不同需求；\n",
    "* 转换（Transformation）：进行 Log 或者 Power 变换，消除异质性；\n",
    "\n",
    "## Centering\n",
    "公式： $\\widetilde{x}_i=x_i-\\overline{x}$\n",
    "\n",
    "常被称为**中心化**，将数据从均值附近变换到0附近，对存在异方差的数据处理效果不佳。\n",
    "\n",
    "## AutoScaling\n",
    "公式: $\\widetilde{x}_i=\\frac{x_i-\\overline{x}}{s}$\n",
    "\n",
    "其中s是数据的标准差。常被称为**标准化**(Standardization)。将数据变为均值为0，方差为1的数据集。\n",
    "\n",
    "## Min-Max Scaling\n",
    "公式：$\\widetilde{x}_i=\\frac{x_i-x_{min}}{x_{max}-x_{min}}$\n",
    "\n",
    "离差标准化，常被翻译为**归一化**(Normalization)，将数据缩放到[0,1]区间。对异常值敏感。\n",
    "\n",
    "## L-Normalization\n",
    "这类标准化将每个样本缩放到单位范数，主要有L1-normalization（L1范数），L2-normalization（L2范数）等。其主要思想是对每个样本计算其p范数，然后对该样本中每个元素除以该范数，这样处理的结果是使得每个处理后样本的p范数等于1.\n",
    "\n",
    "${\\Vert X \\Vert}_p = \\sqrt[p]{{\\vert x_1 \\vert}^p + {\\vert x_2 \\vert}^p + ... + {\\vert x_n \\vert}^p}$\n",
    "\n",
    "该方法主要应用于文本分类和聚类中。\n",
    "\n",
    "## RangeScaling\n",
    "公式：$\\widetilde{x}_i=\\frac{x_i-\\overline{x}}{x_{max}-x_{min}}$\n",
    "\n",
    "比较变化量相对于变化范围的比例以及变化方向；对异常值敏感。\n",
    "\n",
    "## ParetoScaling\n",
    "公式: $\\widetilde{x}_i=\\frac{x_i-\\overline{x}}{\\sqrt{s}}$\n",
    "\n",
    "相对于AutoScaling保留了更多的原始值变化，对大的倍数差异敏感。\n",
    "\n",
    "## VastScaling\n",
    "公式: $\\widetilde{x}_i=\\frac{x_i-\\overline{x}}{s} \\cdot \\frac{\\overline{x}}{s}$\n",
    "\n",
    "关注变动小的变量。\n",
    "\n",
    "## LevelScaling\n",
    "公式: $\\widetilde{x}_i=\\frac{x_i-\\overline{x}}{\\overline{x}}$\n",
    "\n",
    "比较变化量相对均值的比例，适合用来发现生物标志物。\n",
    "\n",
    "## LogTransformation\n",
    "公式：\n",
    "\n",
    "$\\widetilde{x}_i=\\log{x_i}$\n",
    "\n",
    "$\\widetilde{x}_i = \\widetilde{x}_i - \\overline{\\widetilde{x}}$\n",
    "\n",
    "消除异方差以及大的倍数差异影响，使数据线性化。\n",
    "\n",
    "## PowerTransformation\n",
    "公式：\n",
    "\n",
    "$\\widetilde{x}_i=\\sqrt{x_i}$\n",
    "\n",
    "$\\widetilde{x}_i = \\widetilde{x}_i - \\overline{\\widetilde{x}}$\n",
    "\n",
    "消除异方差的影响，使数据线性化。选择合适的根次很重要。\n",
    "\n",
    "\n",
    "## 参考资料\n",
    "https://zhuanlan.zhihu.com/p/222331894\n",
    "https://scikit-learn.org/stable/modules/preprocessing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         -1.22474487  1.33630621]\n",
      " [ 1.22474487  0.         -0.26726124]\n",
      " [-1.22474487  1.22474487 -1.06904497]]\n",
      "[0. 0. 0.]\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "# scikit-learn中的preprocessing模块提供了一些标准化的方法\n",
    "\n",
    "# 1. Standardization\n",
    "X_train = np.array([[ 1., -1.,  2.], [ 2.,  0.,  0.], [ 0.,  1., -1.]])\n",
    "# 这里fit其实没有做转换，相当于只是约定了一个后续transform操作的数据形状\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "X_scaled = scaler.transform(X_train)\n",
    "print(X_scaled)\n",
    "print(X_scaled.mean(axis=0))\n",
    "print(X_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5        0.         1.        ]\n",
      " [1.         0.5        0.33333333]\n",
      " [0.         1.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 缩放到[0,1]之间\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "print(X_train_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5 -1.   1. ]\n",
      " [ 1.   0.   0. ]\n",
      " [ 0.   1.  -0.5]]\n"
     ]
    }
   ],
   "source": [
    "# 缩放到[-1,1]之间，每个特征除以最大值的绝对值\n",
    "max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "X_train_maxabs = max_abs_scaler.fit_transform(X_train)\n",
    "print(X_train_maxabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.40824829 -0.40824829  0.81649658]\n",
      " [ 1.          0.          0.        ]\n",
      " [ 0.          0.70710678 -0.70710678]]\n"
     ]
    }
   ],
   "source": [
    "# L范数\n",
    "norm_scaler = preprocessing.Normalizer(norm=\"l2\")\n",
    "X_train_norm = norm_scaler.fit_transform(X_train)\n",
    "print(X_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.69314718]\n",
      " [1.09861229 1.38629436]]\n"
     ]
    }
   ],
   "source": [
    "# 自定义对数变换\n",
    "log_scaler = preprocessing.FunctionTransformer(np.log1p) # log(1+x)\n",
    "X = np.array([[0, 1], [2, 3]])\n",
    "X_log = log_scaler.fit_transform(X)\n",
    "print(X_log)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9599e80ef5032cb9b87bb7c40eb068985babe7e8bc8c4216612da36441f484a2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
